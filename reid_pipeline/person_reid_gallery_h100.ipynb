{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Person Re-ID Gallery Pipeline (H100)\n",
        "\n",
        "This notebook demonstrates a DeepStream pipeline that:\n",
        "1. **Detects persons** using a primary detector (PGIE)\n",
        "2. **Tracks persons** across frames using nvtracker\n",
        "3. **Extracts Re-ID embeddings** using OSNet as an SGIE\n",
        "4. **Stores embeddings** in ChromaDB when tracks end\n",
        "\n",
        "## Pipeline Architecture\n",
        "\n",
        "```\n",
        "filesrc → h264parse → nvv4l2decoder → nvstreammux → \n",
        "pgie (person detector) → nvtracker → \n",
        "sgie (OSNet Re-ID) → \n",
        "nvvideoconvert → nvdsosd → nvvideoconvert → \n",
        "x264enc → filesink\n",
        "```\n",
        "\n",
        "## Embedding Strategy: Store on Track End\n",
        "\n",
        "- Accumulate embeddings in memory while person is tracked\n",
        "- Average embeddings when track ends (30 frame grace period)\n",
        "- Store single averaged embedding per person in ChromaDB\n",
        "- Finalize all remaining tracks at end of stream (EOS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before running this notebook:\n",
        "\n",
        "\n",
        "1. **Install ChromaDB** (inside container):\n",
        "   ```bash\n",
        "   pip install chromadb\n",
        "   ```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Install dependencies (run once)\n",
        "!pip install chromadb -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Import Required Libraries\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import ctypes\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import chromadb\n",
        "\n",
        "sys.path.append('/opt/nvidia/deepstream/deepstream-8.0/sources/deepstream_python_apps/apps')\n",
        "\n",
        "import gi\n",
        "gi.require_version('Gst', '1.0')\n",
        "from gi.repository import GObject, Gst, GLib\n",
        "from common.bus_call import bus_call\n",
        "import pyds\n",
        "\n",
        "Gst.init(None)\n",
        "\n",
        "print(f\"GStreamer version: {Gst.version_string()}\")\n",
        "print(f\"ChromaDB version: {chromadb.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Configuration\n",
        "\n",
        "# Class IDs from PGIE\n",
        "PGIE_CLASS_ID_VEHICLE = 0\n",
        "PGIE_CLASS_ID_BICYCLE = 1\n",
        "PGIE_CLASS_ID_PERSON = 2\n",
        "PGIE_CLASS_ID_ROADSIGN = 3\n",
        "\n",
        "# Paths - adjust as needed\n",
        "PIPELINE_DIR = '/app/notebooks/reid_pipeline'\n",
        "INPUT_VIDEO = '/opt/nvidia/deepstream/deepstream-8.0/samples/streams/sample_720p.h264'\n",
        "OUTPUT_VIDEO = f'{PIPELINE_DIR}/output_reid.mp4'\n",
        "\n",
        "# Model configs\n",
        "PGIE_CONFIG = '/opt/nvidia/deepstream/deepstream-8.0/sources/deepstream_python_apps/apps/deepstream-test1/dstest1_pgie_config.txt'\n",
        "REID_SGIE_CONFIG = f'{PIPELINE_DIR}/reid_sgie_config.txt'\n",
        "\n",
        "# Tracker config\n",
        "TRACKER_LIB = '/opt/nvidia/deepstream/deepstream-8.0/lib/libnvds_nvmultiobjecttracker.so'\n",
        "TRACKER_CONFIG = '/opt/nvidia/deepstream/deepstream-8.0/samples/configs/deepstream-app/config_tracker_NvDCF_perf.yml'\n",
        "\n",
        "# Re-ID settings\n",
        "EMBEDDING_DIM = 512  # OSNet output dimension\n",
        "GRACE_FRAMES = 30    # Frames to wait before declaring track ended\n",
        "\n",
        "# ChromaDB gallery path\n",
        "GALLERY_PATH = f'{PIPELINE_DIR}/gallery'\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Input video: {INPUT_VIDEO}\")\n",
        "print(f\"  Output video: {OUTPUT_VIDEO}\")\n",
        "print(f\"  PGIE config: {PGIE_CONFIG}\")\n",
        "print(f\"  Re-ID SGIE config: {REID_SGIE_CONFIG}\")\n",
        "print(f\"  Embedding dim: {EMBEDDING_DIM}\")\n",
        "print(f\"  Grace period: {GRACE_FRAMES} frames\")\n",
        "print(f\"  Gallery path: {GALLERY_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Check if OSNet model exists\n",
        "\n",
        "osnet_path = f'{PIPELINE_DIR}/models/osnet/osnet_x1_0.onnx'\n",
        "if os.path.exists(osnet_path):\n",
        "    print(f\"OSNet model found: {osnet_path}\")\n",
        "    print(f\"  Size: {os.path.getsize(osnet_path) / (1024*1024):.2f} MB\")\n",
        "else:\n",
        "    print(f\"WARNING: OSNet model NOT found at {osnet_path}\")\n",
        "    print(\"\\nPlease export and copy the model:\")\n",
        "    print(\"1. Run export_osnet.py outside the container\")\n",
        "    print(\"2. Copy osnet_x1_0.onnx to models/osnet/\")\n",
        "    print(\"\\nThe pipeline will fail without the model.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Initialize ChromaDB\n",
        "\n",
        "# Create persistent ChromaDB client\n",
        "chroma_client = chromadb.PersistentClient(path=GALLERY_PATH)\n",
        "\n",
        "# Create or get the embeddings collection\n",
        "# Using cosine similarity for Re-ID (embeddings are typically L2 normalized)\n",
        "collection = chroma_client.get_or_create_collection(\n",
        "    name=\"person_embeddings\",\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "print(f\"ChromaDB initialized at: {GALLERY_PATH}\")\n",
        "print(f\"Collection: person_embeddings\")\n",
        "print(f\"Existing entries: {collection.count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Track Management - Global State\n",
        "\n",
        "# These persist across probe calls\n",
        "active_tracks = {}       # {track_id: [embedding1, embedding2, ...]}\n",
        "track_last_seen = {}     # {track_id: last_frame_num}\n",
        "track_metadata = {}      # {track_id: {first_frame, best_confidence, best_bbox}}\n",
        "finalized_count = 0      # Counter for stored embeddings\n",
        "\n",
        "def reset_tracking_state():\n",
        "    \"\"\"Reset all tracking state (call before running pipeline)\"\"\"\n",
        "    global active_tracks, track_last_seen, track_metadata, finalized_count\n",
        "    active_tracks = {}\n",
        "    track_last_seen = {}\n",
        "    track_metadata = {}\n",
        "    finalized_count = 0\n",
        "    print(\"Tracking state reset\")\n",
        "\n",
        "print(\"Track management state initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Embedding Extraction Function\n",
        "\n",
        "def extract_reid_embedding(obj_meta):\n",
        "    \"\"\"\n",
        "    Extract Re-ID embedding from object's tensor metadata.\n",
        "    \n",
        "    The Re-ID SGIE outputs tensor data (not class labels) because\n",
        "    we set output-tensor-meta=1 in the config.\n",
        "    \n",
        "    Args:\n",
        "        obj_meta: NvDsObjectMeta for a detected person\n",
        "        \n",
        "    Returns:\n",
        "        numpy array of shape (512,) or None if extraction fails\n",
        "    \"\"\"\n",
        "    l_user = obj_meta.obj_user_meta_list\n",
        "    \n",
        "    while l_user is not None:\n",
        "        try:\n",
        "            user_meta = pyds.NvDsUserMeta.cast(l_user.data)\n",
        "        except StopIteration:\n",
        "            break\n",
        "        \n",
        "        # Check if this is tensor output metadata\n",
        "        if user_meta.base_meta.meta_type != pyds.NvDsMetaType.NVDSINFER_TENSOR_OUTPUT_META:\n",
        "            try:\n",
        "                l_user = l_user.next\n",
        "            except StopIteration:\n",
        "                break\n",
        "            continue\n",
        "        \n",
        "        # Cast to tensor meta\n",
        "        tensor_meta = pyds.NvDsInferTensorMeta.cast(user_meta.user_meta_data)\n",
        "        \n",
        "        # Get the first output layer (embedding)\n",
        "        layer = pyds.get_nvds_LayerInfo(tensor_meta, 0)\n",
        "        \n",
        "        # Get pointer to the buffer\n",
        "        ptr = ctypes.cast(pyds.get_ptr(layer.buffer), ctypes.POINTER(ctypes.c_float))\n",
        "        \n",
        "        # Copy to numpy array (GPU -> CPU)\n",
        "        embedding = np.ctypeslib.as_array(ptr, shape=(EMBEDDING_DIM,)).copy()\n",
        "        \n",
        "        # L2 normalize the embedding\n",
        "        norm = np.linalg.norm(embedding)\n",
        "        if norm > 0:\n",
        "            embedding = embedding / norm\n",
        "        \n",
        "        return embedding\n",
        "        \n",
        "    return None\n",
        "\n",
        "print(\"Embedding extraction function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Track Finalization Function\n",
        "\n",
        "def finalize_track(track_id, source_id=0):\n",
        "    \"\"\"\n",
        "    Finalize a track: average embeddings and store to ChromaDB.\n",
        "    \n",
        "    Called when a track hasn't been seen for GRACE_FRAMES frames,\n",
        "    indicating the person has left the scene.\n",
        "    \n",
        "    Args:\n",
        "        track_id: The tracker's object ID\n",
        "        source_id: Camera/source identifier (for multi-camera)\n",
        "    \"\"\"\n",
        "    global finalized_count\n",
        "    \n",
        "    if track_id not in active_tracks:\n",
        "        return\n",
        "    \n",
        "    embeddings = active_tracks[track_id]\n",
        "    metadata = track_metadata.get(track_id, {})\n",
        "    \n",
        "    if len(embeddings) == 0:\n",
        "        print(f\"  Track {track_id}: No embeddings to store\")\n",
        "        return\n",
        "    \n",
        "    # Average all embeddings for this track\n",
        "    avg_embedding = np.mean(embeddings, axis=0)\n",
        "    \n",
        "    # L2 normalize the averaged embedding\n",
        "    norm = np.linalg.norm(avg_embedding)\n",
        "    if norm > 0:\n",
        "        avg_embedding = avg_embedding / norm\n",
        "    \n",
        "    # Create unique ID for ChromaDB\n",
        "    entry_id = f\"src{source_id}_track{track_id}_{int(time.time()*1000)}\"\n",
        "    \n",
        "    # Store to ChromaDB\n",
        "    collection.add(\n",
        "        embeddings=[avg_embedding.tolist()],\n",
        "        ids=[entry_id],\n",
        "        metadatas=[{\n",
        "            \"track_id\": int(track_id),\n",
        "            \"source_id\": int(source_id),\n",
        "            \"num_frames\": len(embeddings),\n",
        "            \"first_frame\": metadata.get('first_frame', 0),\n",
        "            \"last_frame\": metadata.get('last_frame', 0),\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        }]\n",
        "    )\n",
        "    \n",
        "    finalized_count += 1\n",
        "    print(f\"  Stored track {track_id}: {len(embeddings)} frames averaged -> {entry_id}\")\n",
        "    \n",
        "    # Cleanup\n",
        "    del active_tracks[track_id]\n",
        "    if track_id in track_last_seen:\n",
        "        del track_last_seen[track_id]\n",
        "    if track_id in track_metadata:\n",
        "        del track_metadata[track_id]\n",
        "\n",
        "\n",
        "def finalize_all_tracks(source_id=0):\n",
        "    \"\"\"\n",
        "    Finalize all remaining active tracks.\n",
        "    Called at end of stream (EOS) to ensure no data is lost.\n",
        "    \"\"\"\n",
        "    print(f\"\\nFinalizing {len(active_tracks)} remaining tracks...\")\n",
        "    for track_id in list(active_tracks.keys()):\n",
        "        finalize_track(track_id, source_id)\n",
        "    print(f\"Total embeddings stored: {finalized_count}\")\n",
        "\n",
        "print(\"Track finalization functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Buffer Probe Function\n",
        "\n",
        "def reid_sink_pad_buffer_probe(pad, info, u_data):\n",
        "    \"\"\"\n",
        "    Buffer probe to extract Re-ID embeddings and manage tracks.\n",
        "    \n",
        "    This function is called for every frame passing through the pipeline.\n",
        "    It:\n",
        "    1. Extracts embeddings for each detected person\n",
        "    2. Accumulates embeddings in active_tracks\n",
        "    3. Checks for ended tracks (grace period expired)\n",
        "    4. Finalizes and stores ended tracks to ChromaDB\n",
        "    \"\"\"\n",
        "    global active_tracks, track_last_seen, track_metadata\n",
        "    \n",
        "    gst_buffer = info.get_buffer()\n",
        "    if not gst_buffer:\n",
        "        return Gst.PadProbeReturn.OK\n",
        "    \n",
        "    batch_meta = pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
        "    l_frame = batch_meta.frame_meta_list\n",
        "    \n",
        "    while l_frame is not None:\n",
        "        try:\n",
        "            frame_meta = pyds.NvDsFrameMeta.cast(l_frame.data)\n",
        "        except StopIteration:\n",
        "            break\n",
        "        \n",
        "        frame_num = frame_meta.frame_num\n",
        "        source_id = frame_meta.source_id\n",
        "        current_track_ids = set()\n",
        "        person_count = 0\n",
        "        embedding_count = 0\n",
        "        \n",
        "        l_obj = frame_meta.obj_meta_list\n",
        "        \n",
        "        while l_obj is not None:\n",
        "            try:\n",
        "                obj_meta = pyds.NvDsObjectMeta.cast(l_obj.data)\n",
        "            except StopIteration:\n",
        "                break\n",
        "            \n",
        "            # Only process persons\n",
        "            if obj_meta.class_id == PGIE_CLASS_ID_PERSON:\n",
        "                person_count += 1\n",
        "                track_id = obj_meta.object_id\n",
        "                current_track_ids.add(track_id)\n",
        "                \n",
        "                # Extract Re-ID embedding\n",
        "                embedding = extract_reid_embedding(obj_meta)\n",
        "                \n",
        "                if embedding is not None:\n",
        "                    embedding_count += 1\n",
        "                    \n",
        "                    # Initialize track if new\n",
        "                    if track_id not in active_tracks:\n",
        "                        active_tracks[track_id] = []\n",
        "                        track_metadata[track_id] = {\n",
        "                            'first_frame': frame_num,\n",
        "                            'source_id': source_id\n",
        "                        }\n",
        "                    \n",
        "                    # Accumulate embedding\n",
        "                    active_tracks[track_id].append(embedding)\n",
        "                    track_last_seen[track_id] = frame_num\n",
        "                    track_metadata[track_id]['last_frame'] = frame_num\n",
        "            \n",
        "            try:\n",
        "                l_obj = l_obj.next\n",
        "            except StopIteration:\n",
        "                break\n",
        "        \n",
        "        # Check for ended tracks (not seen for GRACE_FRAMES)\n",
        "        ended_tracks = []\n",
        "        for track_id, last_frame in list(track_last_seen.items()):\n",
        "            if frame_num - last_frame > GRACE_FRAMES:\n",
        "                ended_tracks.append(track_id)\n",
        "        \n",
        "        # Finalize ended tracks\n",
        "        for track_id in ended_tracks:\n",
        "            finalize_track(track_id, source_id)\n",
        "        \n",
        "        # Print progress every 100 frames\n",
        "        if frame_num % 100 == 0:\n",
        "            print(f\"Frame {frame_num}: {person_count} persons, {embedding_count} embeddings, \"\n",
        "                  f\"{len(active_tracks)} active tracks, {finalized_count} stored\")\n",
        "        \n",
        "        try:\n",
        "            l_frame = l_frame.next\n",
        "        except StopIteration:\n",
        "            break\n",
        "    \n",
        "    return Gst.PadProbeReturn.OK\n",
        "\n",
        "print(\"Buffer probe function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10: Helper function to create GStreamer elements\n",
        "\n",
        "def make_elm_or_print_err(factoryname, name, printedname, detail=\"\"):\n",
        "    \"\"\"Create a GStreamer element or print error message\"\"\"\n",
        "    print(f\"Creating {printedname}...\")\n",
        "    elm = Gst.ElementFactory.make(factoryname, name)\n",
        "    if not elm:\n",
        "        sys.stderr.write(f\"Unable to create {printedname}\\n\")\n",
        "        if detail:\n",
        "            sys.stderr.write(detail)\n",
        "    return elm\n",
        "\n",
        "print(\"Helper function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: Create Pipeline Elements\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATING PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Reset tracking state\n",
        "reset_tracking_state()\n",
        "\n",
        "# Create Pipeline\n",
        "pipeline = Gst.Pipeline()\n",
        "if not pipeline:\n",
        "    sys.stderr.write(\"Unable to create Pipeline\\n\")\n",
        "\n",
        "# Source elements\n",
        "source = make_elm_or_print_err(\"filesrc\", \"file-source\", \"File Source\")\n",
        "h264parser = make_elm_or_print_err(\"h264parse\", \"h264-parser\", \"H264 Parser\")\n",
        "decoder = make_elm_or_print_err(\"nvv4l2decoder\", \"nvv4l2-decoder\", \"NV Decoder\")\n",
        "\n",
        "# Stream muxer\n",
        "streammux = make_elm_or_print_err(\"nvstreammux\", \"stream-muxer\", \"Stream Muxer\")\n",
        "\n",
        "# Primary inference (person detection)\n",
        "pgie = make_elm_or_print_err(\"nvinfer\", \"primary-inference\", \"Primary Inference (Person Detector)\")\n",
        "\n",
        "# Tracker\n",
        "tracker = make_elm_or_print_err(\"nvtracker\", \"tracker\", \"NV Tracker\")\n",
        "\n",
        "# Secondary inference (Re-ID)\n",
        "reid_sgie = make_elm_or_print_err(\"nvinfer\", \"reid-inference\", \"Re-ID SGIE (OSNet)\")\n",
        "\n",
        "# Video processing\n",
        "nvvidconv = make_elm_or_print_err(\"nvvideoconvert\", \"convertor\", \"NV Video Converter 1\")\n",
        "nvosd = make_elm_or_print_err(\"nvdsosd\", \"onscreendisplay\", \"On-Screen Display\")\n",
        "nvvidconv2 = make_elm_or_print_err(\"nvvideoconvert\", \"convertor2\", \"NV Video Converter 2\")\n",
        "capsfilter = make_elm_or_print_err(\"capsfilter\", \"caps\", \"Caps Filter\")\n",
        "\n",
        "# H100: Software encoder path\n",
        "sw_videoconvert = make_elm_or_print_err(\"videoconvert\", \"sw-videoconvert\", \"Software Video Converter\")\n",
        "encoder = make_elm_or_print_err(\"x264enc\", \"encoder\", \"H264 Software Encoder\")\n",
        "h264parser2 = make_elm_or_print_err(\"h264parse\", \"h264-parser2\", \"H264 Parser 2\")\n",
        "mp4mux = make_elm_or_print_err(\"mp4mux\", \"mp4mux\", \"MP4 Muxer\")\n",
        "sink = make_elm_or_print_err(\"filesink\", \"filesink\", \"File Sink\")\n",
        "\n",
        "print(\"\\nAll elements created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 12: Configure Pipeline Elements\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONFIGURING ELEMENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Source\n",
        "source.set_property('location', INPUT_VIDEO)\n",
        "print(f\"Source: {INPUT_VIDEO}\")\n",
        "\n",
        "# Stream muxer\n",
        "streammux.set_property('width', 1920)\n",
        "streammux.set_property('height', 1080)\n",
        "streammux.set_property('batch-size', 1)\n",
        "streammux.set_property('batched-push-timeout', 4000000)\n",
        "print(\"Stream muxer: 1920x1080, batch-size=1\")\n",
        "\n",
        "# Primary inference (person detector)\n",
        "pgie.set_property('config-file-path', PGIE_CONFIG)\n",
        "print(f\"PGIE config: {PGIE_CONFIG}\")\n",
        "\n",
        "# Tracker\n",
        "tracker.set_property('tracker-width', 640)\n",
        "tracker.set_property('tracker-height', 384)\n",
        "tracker.set_property('ll-lib-file', TRACKER_LIB)\n",
        "tracker.set_property('ll-config-file', TRACKER_CONFIG)\n",
        "tracker.set_property('gpu-id', 0)\n",
        "print(f\"Tracker: NvDCF\")\n",
        "\n",
        "# Re-ID SGIE\n",
        "reid_sgie.set_property('config-file-path', REID_SGIE_CONFIG)\n",
        "print(f\"Re-ID SGIE config: {REID_SGIE_CONFIG}\")\n",
        "\n",
        "# Caps filter (H100: CPU memory for x264enc)\n",
        "caps = Gst.Caps.from_string(\"video/x-raw, format=I420\")\n",
        "capsfilter.set_property(\"caps\", caps)\n",
        "print(\"Caps: I420 (CPU memory)\")\n",
        "\n",
        "# Encoder\n",
        "encoder.set_property('bitrate', 4000)\n",
        "encoder.set_property('speed-preset', 'ultrafast')\n",
        "encoder.set_property('tune', 'zerolatency')\n",
        "print(\"Encoder: x264enc @ 4 Mbps\")\n",
        "\n",
        "# Sink\n",
        "sink.set_property('location', OUTPUT_VIDEO)\n",
        "sink.set_property('sync', False)\n",
        "print(f\"Output: {OUTPUT_VIDEO}\")\n",
        "\n",
        "print(\"\\nAll elements configured!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 13: Build Pipeline\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BUILDING PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Add elements to pipeline\n",
        "print(\"Adding elements to pipeline...\")\n",
        "pipeline.add(source)\n",
        "pipeline.add(h264parser)\n",
        "pipeline.add(decoder)\n",
        "pipeline.add(streammux)\n",
        "pipeline.add(pgie)\n",
        "pipeline.add(tracker)\n",
        "pipeline.add(reid_sgie)\n",
        "pipeline.add(nvvidconv)\n",
        "pipeline.add(nvosd)\n",
        "pipeline.add(nvvidconv2)\n",
        "pipeline.add(capsfilter)\n",
        "pipeline.add(sw_videoconvert)\n",
        "pipeline.add(encoder)\n",
        "pipeline.add(h264parser2)\n",
        "pipeline.add(mp4mux)\n",
        "pipeline.add(sink)\n",
        "print(\"All elements added\")\n",
        "\n",
        "# Link elements\n",
        "print(\"\\nLinking elements...\")\n",
        "\n",
        "# Source -> Parser -> Decoder\n",
        "source.link(h264parser)\n",
        "h264parser.link(decoder)\n",
        "print(\"Linked: source -> h264parser -> decoder\")\n",
        "\n",
        "# Decoder -> Streammux (special pad handling)\n",
        "sinkpad = streammux.request_pad_simple(\"sink_0\")\n",
        "srcpad = decoder.get_static_pad(\"src\")\n",
        "srcpad.link(sinkpad)\n",
        "print(\"Linked: decoder -> streammux\")\n",
        "\n",
        "# Streammux -> PGIE -> Tracker -> Re-ID SGIE\n",
        "streammux.link(pgie)\n",
        "pgie.link(tracker)\n",
        "tracker.link(reid_sgie)\n",
        "print(\"Linked: streammux -> pgie -> tracker -> reid_sgie\")\n",
        "\n",
        "# Re-ID SGIE -> Video processing -> Encoder -> Sink\n",
        "reid_sgie.link(nvvidconv)\n",
        "nvvidconv.link(nvosd)\n",
        "nvosd.link(nvvidconv2)\n",
        "nvvidconv2.link(capsfilter)\n",
        "capsfilter.link(sw_videoconvert)\n",
        "sw_videoconvert.link(encoder)\n",
        "encoder.link(h264parser2)\n",
        "h264parser2.link(mp4mux)\n",
        "mp4mux.link(sink)\n",
        "print(\"Linked: reid_sgie -> nvvidconv -> nvosd -> encoder -> sink\")\n",
        "\n",
        "print(\"\\nPipeline built successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 14: Attach Buffer Probe\n",
        "\n",
        "# Attach probe to Re-ID SGIE's source pad\n",
        "# This is where we extract embeddings after Re-ID inference\n",
        "reid_sgie_srcpad = reid_sgie.get_static_pad(\"src\")\n",
        "if not reid_sgie_srcpad:\n",
        "    sys.stderr.write(\"Unable to get src pad of reid_sgie\\n\")\n",
        "else:\n",
        "    reid_sgie_srcpad.add_probe(Gst.PadProbeType.BUFFER, reid_sink_pad_buffer_probe, 0)\n",
        "    print(\"Buffer probe attached to Re-ID SGIE src pad\")\n",
        "    print(\"Embeddings will be extracted and accumulated here\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 15: Setup Bus Message Handler\n",
        "\n",
        "loop = GLib.MainLoop()\n",
        "bus = pipeline.get_bus()\n",
        "bus.add_signal_watch()\n",
        "bus.connect(\"message\", bus_call, loop)\n",
        "\n",
        "print(\"Bus message handler configured\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 16: Run the Pipeline\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING RE-ID PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Input: {INPUT_VIDEO}\")\n",
        "print(f\"Output video: {OUTPUT_VIDEO}\")\n",
        "print(f\"Gallery: {GALLERY_PATH}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Start pipeline\n",
        "ret = pipeline.set_state(Gst.State.PLAYING)\n",
        "if ret == Gst.StateChangeReturn.FAILURE:\n",
        "    print(\"ERROR: Unable to set pipeline to PLAYING state\")\n",
        "else:\n",
        "    try:\n",
        "        loop.run()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nInterrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {e}\")\n",
        "    finally:\n",
        "        # Finalize all remaining tracks at EOS\n",
        "        finalize_all_tracks(source_id=0)\n",
        "        \n",
        "        # Cleanup\n",
        "        print(\"\\nCleaning up...\")\n",
        "        pipeline.set_state(Gst.State.NULL)\n",
        "        \n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"\\n\" + \"=\"*60)\n",
        "        print(\"PIPELINE COMPLETED\")\n",
        "        print(f\"  Time elapsed: {elapsed_time:.2f} seconds\")\n",
        "        print(f\"  Total embeddings stored: {finalized_count}\")\n",
        "        print(f\"  Gallery entries: {collection.count()}\")\n",
        "        print(f\"  Output video: {OUTPUT_VIDEO}\")\n",
        "        print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 17: View Gallery Statistics\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GALLERY STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "total_entries = collection.count()\n",
        "print(f\"Total entries in gallery: {total_entries}\")\n",
        "\n",
        "if total_entries > 0:\n",
        "    all_data = collection.get(include=['metadatas'])\n",
        "    total_frames = sum(m.get('num_frames', 0) for m in all_data['metadatas'])\n",
        "    avg_frames = total_frames / total_entries if total_entries > 0 else 0\n",
        "    \n",
        "    print(f\"\\nPer-entry statistics:\")\n",
        "    print(f\"  Average frames per person: {avg_frames:.1f}\")\n",
        "    \n",
        "    print(f\"\\nSample entries (first 5):\")\n",
        "    for i, (entry_id, metadata) in enumerate(zip(all_data['ids'][:5], all_data['metadatas'][:5])):\n",
        "        print(f\"  {i+1}. {entry_id}: Track {metadata.get('track_id')}, {metadata.get('num_frames')} frames\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 18: Query the Gallery (Similarity Search Demo)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GALLERY SEARCH DEMO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if collection.count() > 1:\n",
        "    # Get a random entry to use as query\n",
        "    all_data = collection.get(include=['embeddings', 'metadatas'], limit=1)\n",
        "    query_embedding = all_data['embeddings'][0]\n",
        "    query_id = all_data['ids'][0]\n",
        "    \n",
        "    print(f\"Query: {query_id}\")\n",
        "    \n",
        "    # Search for similar persons\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=5,\n",
        "        include=['metadatas', 'distances']\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nTop 5 similar entries:\")\n",
        "    for i, (result_id, distance, metadata) in enumerate(zip(\n",
        "        results['ids'][0], results['distances'][0], results['metadatas'][0]\n",
        "    )):\n",
        "        similarity = 1 - distance  # Cosine distance to similarity\n",
        "        print(f\"  {i+1}. {result_id} - Similarity: {similarity:.4f}\")\n",
        "else:\n",
        "    print(\"Gallery has < 2 entries. Run the pipeline first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 19: Clear Gallery (Optional - Uncomment to use)\n",
        "\n",
        "# WARNING: This deletes all stored embeddings!\n",
        "# Uncomment the lines below to clear the gallery\n",
        "\n",
        "# print(\"Clearing gallery...\")\n",
        "# chroma_client.delete_collection(\"person_embeddings\")\n",
        "# collection = chroma_client.create_collection(\n",
        "#     name=\"person_embeddings\",\n",
        "#     metadata={\"hnsw:space\": \"cosine\"}\n",
        "# )\n",
        "# print(f\"Gallery cleared. New count: {collection.count()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 17: View Gallery Statistics\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GALLERY STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "total_entries = collection.count()\n",
        "print(f\"Total entries in gallery: {total_entries}\")\n",
        "\n",
        "if total_entries > 0:\n",
        "    # Get all entries\n",
        "    all_data = collection.get(include=['metadatas'])\n",
        "    \n",
        "    # Analyze\n",
        "    total_frames = sum(m.get('num_frames', 0) for m in all_data['metadatas'])\n",
        "    avg_frames = total_frames / total_entries if total_entries > 0 else 0\n",
        "    \n",
        "    print(f\"\\nPer-entry statistics:\")\n",
        "    print(f\"  Average frames per person: {avg_frames:.1f}\")\n",
        "    print(f\"  Total frames processed: {total_frames}\")\n",
        "    \n",
        "    print(f\"\\nSample entries:\")\n",
        "    for i, (entry_id, metadata) in enumerate(zip(all_data['ids'][:5], all_data['metadatas'][:5])):\n",
        "        print(f\"  {entry_id}:\")\n",
        "        print(f\"    Track ID: {metadata.get('track_id')}\")\n",
        "        print(f\"    Frames: {metadata.get('first_frame')} - {metadata.get('last_frame')} ({metadata.get('num_frames')} total)\")\n",
        "        print(f\"    Timestamp: {metadata.get('timestamp')}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
